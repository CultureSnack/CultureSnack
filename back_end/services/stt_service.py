import os
import librosa
import soundfile as sf
import shutil
import numpy as np
import requests

class AudioService:
    def __init__(self):
        self.openai_api_key = (os.environ.get("OPENAI_API_KEY") or "").strip()
        self.api_url = os.environ.get(
            "WHISPER_API_URL", "https://api.openai.com/v1/audio/transcriptions"
        )

    def convert_audio(self, input_file: str, output_file: str) -> str:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ 16kHz PCM wavë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥.
        output_file íŒŒë¼ë¯¸í„°ê°€ wavê°€ ì•„ë‹ˆë©´ í™•ì¥ì ê°•ì œë¡œ wavë¡œ ë³€ê²½.
        ë°˜í™˜ê°’: ì‹¤ì œ ì €ì¥ëœ wav íŒŒì¼ ê²½ë¡œ(str)
        """
        try:
            print(f"ğŸ”„ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹œì‘: {input_file} -> {output_file}")
            audio, original_sr = librosa.load(input_file, sr=None)
            print(f"âœ… ì›ë³¸ ì˜¤ë””ì˜¤ ë¡œë“œ: {len(audio)} samples, {original_sr}Hz")

            target_sr = 16000
            if original_sr != target_sr:
                audio = librosa.resample(audio, orig_sr=original_sr, target_sr=target_sr)
                print(f"ğŸ”„ ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ: {original_sr}Hz -> {target_sr}Hz")

            # output_file í™•ì¥ìë¥¼ ë¬´ì¡°ê±´ .wavë¡œ
            if not output_file.lower().endswith('.wav'):
                output_file = output_file.rsplit('.', 1)[0] + '.wav'

            sf.write(output_file, audio, target_sr, format='WAV', subtype='PCM_16')
            print(f"âœ… WAV ì €ì¥ ì™„ë£Œ: {output_file}")
            return output_file

        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
            if self._copy_file(input_file, output_file):
                return output_file
            return ""

    def _copy_file(self, src: str, dst: str) -> bool:
        """íŒŒì¼ ë³µì‚¬ (ë³€í™˜ ì‹¤íŒ¨ì‹œ ëŒ€ì•ˆ)"""
        try:
            shutil.copy2(src, dst)
            print(f"âœ… íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: {src} -> {dst}")
            return True
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: {e}")
            return False

    def transcribe_audio(self, file_path: str) -> str:
        """
        Whisper API(OpenAI ë“±)ë¡œë§Œ ë™ì‘! 
        file_pathëŠ” ë°˜ë“œì‹œ wav íŒŒì¼ì´ì–´ì•¼ í•¨.
        """
        try:
            print(f"ğŸŒ Whisper API ìš”ì²­: {file_path}")
            headers = {"Authorization": f"Bearer {self.openai_api_key}"}
            files = {
                'file': open(file_path, 'rb'),
                'model': (None, 'whisper-1'),
                'language': (None, 'ko')
            }
            response = requests.post(self.api_url, headers=headers, files=files)
            if response.ok:
                transcript = response.json().get("text", "")
                print(f"âœ… Whisper API ì¸ì‹ ê²°ê³¼: {transcript}")
                return transcript
            else:
                print(f"âŒ Whisper API ì‹¤íŒ¨: {response.status_code}, {response.text}")
                return ""
        except Exception as e:
            print(f"âŒ Whisper API ì—ëŸ¬: {e}")
            return ""

# ========== ì‚¬ìš© ì˜ˆì‹œ ==========
# audio_service = AudioService()
# wav_path = audio_service.convert_audio("origin.mp3", "converted.wav")  # ì…ë ¥ í™•ì¥ì ìƒê´€ì—†ì´ .wavë¡œ ë³€í™˜
# result = audio_service.transcribe_audio(wav_path)
# print(result)

# ========== ì£¼ì„ ì²˜ë¦¬ëœ Whisper ì½”ë“œ ==========

# import whisper
# import torch
# import librosa
# import numpy as np
# import os

# # ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì €ì¥ (í•„ìš”í•  ë•Œë§Œ ë¡œë”©)
# _model = None

# def _get_model():
#     """ëª¨ë¸ì„ ì§€ì—° ë¡œë”©"""
#     global _model
#     if _model is None:
#         print("ğŸ¤ Whisper base ëª¨ë¸ ë¡œë”© ì‹œì‘...")
#         _model = whisper.load_model("base", device="cuda" if torch.cuda.is_available() else "cpu")
#         print("âœ… Whisper base ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
#     return _model

# def transcribe_audio(file_path: str) -> str:
#     try:
#         print(f"ğŸ“ ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")
        
#         # ffmpeg ì—†ì´ librosaë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ
#         print("ğŸ”„ librosaë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”©...")
#         audio, sr = librosa.load(file_path, sr=16000)  # WhisperëŠ” 16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì‚¬ìš©
#         print(f"âœ… ì˜¤ë””ì˜¤ ë¡œë”© ì™„ë£Œ: {len(audio)} samples, {sr}Hz")
        
#         model = _get_model()
#         print("ğŸ”„ ìŒì„± ì¸ì‹ ì‹œì‘...")
        
#         # ì§ì ‘ ì˜¤ë””ì˜¤ ë°°ì—´ì„ Whisperì— ì „ë‹¬
#         result = model.transcribe(audio, language="ko")
#         transcript = result["text"]
#         print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: {transcript}")
#         return transcript
#     except Exception as e:
#         print(f"âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
#         import traceback
#         print(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
#         # ë°±ì—…: ffmpegê°€ ìˆë‹¤ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‹œë„
#         try:
#             print("ğŸ”„ ë°±ì—… ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...")
#             model = _get_model()
#             result = model.transcribe(file_path, language="ko")
#             transcript = result["text"]
#             print(f"âœ… ë°±ì—… ë°©ì‹ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì™„ë£Œ: {transcript}")
#             return transcript
#         except Exception as backup_e:
#             print(f"âŒ ë°±ì—… ë°©ì‹ë„ ì‹¤íŒ¨: {backup_e}")
#             return ""