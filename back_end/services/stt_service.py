import whisper
import torch
import librosa
import numpy as np
import os

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì €ì¥ (í•„ìš”í•  ë•Œë§Œ ë¡œë”©)
_model = None

def _get_model():
    """ëª¨ë¸ì„ ì§€ì—° ë¡œë”©"""
    global _model
    if _model is None:
        print("ğŸ¤ Whisper base ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        _model = whisper.load_model("base", device="cuda" if torch.cuda.is_available() else "cpu")
        print("âœ… Whisper base ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    return _model

def transcribe_audio(file_path: str) -> str:
    try:
        print(f"ğŸ“ ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")
        
        # ffmpeg ì—†ì´ librosaë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ
        print("ğŸ”„ librosaë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”©...")
        audio, sr = librosa.load(file_path, sr=16000)  # WhisperëŠ” 16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì‚¬ìš©
        print(f"âœ… ì˜¤ë””ì˜¤ ë¡œë”© ì™„ë£Œ: {len(audio)} samples, {sr}Hz")
        
        model = _get_model()
        print("ğŸ”„ ìŒì„± ì¸ì‹ ì‹œì‘...")
        
        # ì§ì ‘ ì˜¤ë””ì˜¤ ë°°ì—´ì„ Whisperì— ì „ë‹¬
        result = model.transcribe(audio, language="ko")
        transcript = result["text"]
        print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: {transcript}")
        return transcript
    except Exception as e:
        print(f"âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
        # ë°±ì—…: ffmpegê°€ ìˆë‹¤ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‹œë„
        try:
            print("ğŸ”„ ë°±ì—… ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...")
            model = _get_model()
            result = model.transcribe(file_path, language="ko")
            transcript = result["text"]
            print(f"âœ… ë°±ì—… ë°©ì‹ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì™„ë£Œ: {transcript}")
            return transcript
        except Exception as backup_e:
            print(f"âŒ ë°±ì—… ë°©ì‹ë„ ì‹¤íŒ¨: {backup_e}")
            return ""