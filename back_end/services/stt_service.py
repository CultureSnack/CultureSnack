import os
import librosa
import soundfile as sf
import shutil
import numpy as np
import requests

class AudioService:
    def __init__(self):
        self.openai_api_key = (os.environ.get("OPENAI_API_KEY") or "").strip()
        self.api_url = os.environ.get(
            "WHISPER_API_URL", "https://api.openai.com/v1/audio/transcriptions"
        )

    def convert_audio(self, input_file: str, output_file: str) -> bool:
        try:
            print(f"ğŸ”„ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹œì‘: {input_file} -> {output_file}")
            audio, original_sr = librosa.load(input_file, sr=None)
            print(f"âœ… ì›ë³¸ ì˜¤ë””ì˜¤ ë¡œë“œ: {len(audio)} samples, {original_sr}Hz")

            target_sr = 16000
            if original_sr != target_sr:
                audio = librosa.resample(audio, orig_sr=original_sr, target_sr=target_sr)
                print(f"ğŸ”„ ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ: {original_sr}Hz -> {target_sr}Hz")

            if output_file.lower().endswith('.mp3'):
                self._save_as_mp3(audio, target_sr, output_file)
            else:
                sf.write(output_file, audio, target_sr)
            print(f"âœ… ì˜¤ë””ì˜¤ ë³€í™˜ ì™„ë£Œ: {output_file}")
            return True

        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return self._copy_file(input_file, output_file)

    def _save_as_mp3(self, audio, sample_rate, output_file):
        try:
            from pydub import AudioSegment
            audio_int16 = (audio * 32767).astype(np.int16)
            audio_segment = AudioSegment(
                audio_int16.tobytes(),
                frame_rate=sample_rate,
                sample_width=2,
                channels=1
            )
            audio_segment.export(output_file, format="mp3", bitrate="128k")
            print(f"âœ… MP3 ì €ì¥ ì™„ë£Œ: {output_file}")

        except ImportError:
            print("âš ï¸ pydub ì—†ìŒ, WAVë¡œ ì €ì¥")
            wav_file = output_file.replace('.mp3', '.wav')
            sf.write(wav_file, audio, sample_rate)
        except Exception as e:
            print(f"âŒ MP3 ì €ì¥ ì‹¤íŒ¨: {e}")
            wav_file = output_file.replace('.mp3', '.wav')
            sf.write(wav_file, audio, sample_rate)

    def _copy_file(self, src: str, dst: str) -> bool:
        try:
            shutil.copy2(src, dst)
            print(f"âœ… íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: {src} -> {dst}")
            return True
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: {e}")
            return False

    def transcribe_audio(self, file_path: str) -> str:
        """
        Whisper API(OpenAI ë“±)ë¡œë§Œ ë™ì‘!
        ë¡œì»¬ ëª¨ë¸ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
        """
        try:
            print(f"ğŸŒ Whisper API ìš”ì²­: {file_path}")
            headers = {"Authorization": f"Bearer {self.openai_api_key}"}
            files = {
                'file': open(file_path, 'rb'),
                'model': (None, 'whisper-1'),
                'language': (None, 'ko')
            }
            response = requests.post(self.api_url, headers=headers, files=files)
            if response.ok:
                transcript = response.json().get("text", "")
                print(f"âœ… Whisper API ì¸ì‹ ê²°ê³¼: {transcript}")
                return transcript
            else:
                print(f"âŒ Whisper API ì‹¤íŒ¨: {response.status_code}, {response.text}")
                return ""
        except Exception as e:
            print(f"âŒ Whisper API ì—ëŸ¬: {e}")
            return ""

# ========== ì‚¬ìš© ì˜ˆì‹œ ==========
# audio_service = AudioService()
# ë³€í™˜: audio_service.convert_audio("origin.wav", "converted.mp3")
# ì¸ì‹: result = audio_service.transcribe_audio("converted.mp3")
# print(result)


# import whisper
# import torch
# import librosa
# import numpy as np
# import os

# # ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì €ì¥ (í•„ìš”í•  ë•Œë§Œ ë¡œë”©)
# _model = None

# def _get_model():
#     """ëª¨ë¸ì„ ì§€ì—° ë¡œë”©"""
#     global _model
#     if _model is None:
#         print("ğŸ¤ Whisper base ëª¨ë¸ ë¡œë”© ì‹œì‘...")
#         _model = whisper.load_model("base", device="cuda" if torch.cuda.is_available() else "cpu")
#         print("âœ… Whisper base ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
#     return _model

# def transcribe_audio(file_path: str) -> str:
#     try:
#         print(f"ğŸ“ ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")
        
#         # ffmpeg ì—†ì´ librosaë¡œ ì˜¤ë””ì˜¤ ë¡œë“œ
#         print("ğŸ”„ librosaë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”©...")
#         audio, sr = librosa.load(file_path, sr=16000)  # WhisperëŠ” 16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì‚¬ìš©
#         print(f"âœ… ì˜¤ë””ì˜¤ ë¡œë”© ì™„ë£Œ: {len(audio)} samples, {sr}Hz")
        
#         model = _get_model()
#         print("ğŸ”„ ìŒì„± ì¸ì‹ ì‹œì‘...")
        
#         # ì§ì ‘ ì˜¤ë””ì˜¤ ë°°ì—´ì„ Whisperì— ì „ë‹¬
#         result = model.transcribe(audio, language="ko")
#         transcript = result["text"]
#         print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: {transcript}")
#         return transcript
#     except Exception as e:
#         print(f"âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {e}")
#         import traceback
#         print(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
        
#         # ë°±ì—…: ffmpegê°€ ìˆë‹¤ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‹œë„
#         try:
#             print("ğŸ”„ ë°±ì—… ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...")
#             model = _get_model()
#             result = model.transcribe(file_path, language="ko")
#             transcript = result["text"]
#             print(f"âœ… ë°±ì—… ë°©ì‹ìœ¼ë¡œ ìŒì„± ì¸ì‹ ì™„ë£Œ: {transcript}")
#             return transcript
#         except Exception as backup_e:
#             print(f"âŒ ë°±ì—… ë°©ì‹ë„ ì‹¤íŒ¨: {backup_e}")
#             return ""